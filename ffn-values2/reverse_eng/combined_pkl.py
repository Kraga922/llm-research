import pandas as pd
import numpy as np
import pickle
from typing import Dict, List, Tuple, Any, Optional
import torch
from transformers import AutoTokenizer, AutoModel
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

class HarmfulSteeringTokenExtractor:
    """
    Extract tokens that represent harmful layer activations using steering vector methodology.
    Based on activation steering papers like "Representation Engineering" and similar work.
    
    The key insight: steering vectors capture concept directions in activation space.
    By projecting these directions back to vocabulary space, we can find tokens that
    best represent the harmful concept at each layer.
    """
    
    def __init__(self, model_name: str = "gpt2"):
        """
        Initialize the extractor with a specific model
        
        Args:
            model_name: The name of the model (e.g., "gpt2", "meta-llama/Meta-Llama-3.1-8B-Instruct")
        """
        self.model_name = model_name
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # Load model for embedding matrix access
            self.model = AutoModel.from_pretrained(model_name)
            
            # Get vocabulary size and hidden dimension
            self.vocab_size = len(self.tokenizer)
            self.hidden_dim = self.model.config.hidden_size
            
            # Storage for loaded data
            self.activation_data = None
            self.harmful_directions = None
            self.unembedding_matrix = None
            
            self._load_unembedding_matrix()
            
        except Exception as e:
            print(f"Warning: Could not load model {model_name}: {e}")
            print("Will try to work without loading the full model...")
            self.tokenizer = None
            self.model = None
            self.vocab_size = None
            self.hidden_dim = None
            self.unembedding_matrix = None
        
    def _load_unembedding_matrix(self):
        """Load the unembedding matrix (W_U) for projecting to vocabulary space"""
        if self.model is None:
            print("Model not loaded, skipping unembedding matrix loading")
            return
            
        try:
            if hasattr(self.model, 'lm_head'):
                # For models like GPT-2
                self.unembedding_matrix = self.model.lm_head.weight.detach().cpu().numpy()  # [vocab_size, hidden_dim]
            elif hasattr(self.model, 'embed_out'):
                self.unembedding_matrix = self.model.embed_out.weight.detach().cpu().numpy()
            else:
                # Try to get from the embedding layer (transpose for unembedding)
                self.unembedding_matrix = self.model.get_input_embeddings().weight.detach().cpu().numpy()
            
            print(f"Loaded unembedding matrix: {self.unembedding_matrix.shape}")
        except Exception as e:
            print(f"Could not load unembedding matrix: {e}")
            self.unembedding_matrix = None
        
    def load_activation_data(self, pkl_path: str):
        """Load the activation data generated by generate_data_gpt2.py"""
        print(f"Loading activation data from {pkl_path}")
        self.activation_data = pd.read_pickle(pkl_path)
        print(f"Loaded {len(self.activation_data)} sentences with activation data")
        
    def load_harmful_directions(self, pkl_path: str):
        """Load the harmful concept directions generated by harmful.ipynb"""
        print(f"Loading harmful directions from {pkl_path}")
        with open(pkl_path, 'rb') as f:
            self.harmful_directions = pickle.load(f)
        
        # Debug: Print the structure of the loaded file
        print(f"Pickle file structure: {type(self.harmful_directions)}")
        if isinstance(self.harmful_directions, dict):
            print(f"Available keys: {list(self.harmful_directions.keys())}")
        
        # Handle different pickle file formats
        if isinstance(self.harmful_directions, dict):
            # Check for different possible key structures
            concept = self.harmful_directions.get('concept', 'harmful')  # default to 'harmful'
            model_name = self.harmful_directions.get('model_name', 'unknown')
            
            # Look for directions under different possible keys
            if 'directions' in self.harmful_directions:
                directions = self.harmful_directions['directions']
            elif 'layer_directions' in self.harmful_directions:
                directions = self.harmful_directions['layer_directions']
            else:
                # Maybe the directions are stored directly as layer keys
                directions = {k: v for k, v in self.harmful_directions.items() 
                            if isinstance(k, (int, str)) and str(k).lstrip('-').isdigit()}
            
            # Look for hidden layers info
            if 'hidden_layers' in self.harmful_directions:
                hidden_layers = self.harmful_directions['hidden_layers']
            elif 'layers' in self.harmful_directions:
                hidden_layers = self.harmful_directions['layers']
            else:
                # Infer from direction keys
                hidden_layers = list(directions.keys()) if directions else []
            
            # Update the structure to match expected format
            self.harmful_directions = {
                'concept': concept,
                'model_name': model_name,
                'directions': directions,
                'hidden_layers': hidden_layers
            }
            
            print(f"Loaded harmful directions for concept: {concept}")
            print(f"Model: {model_name}")
            print(f"Hidden layers: {hidden_layers}")
            print(f"Number of direction vectors: {len(directions) if directions else 0}")
            
            # Print some details about the direction vectors
            if directions:
                for layer_idx, direction in list(directions.items())[:3]:  # Show first 3
                    if hasattr(direction, 'shape'):
                        print(f"  Layer {layer_idx}: shape {direction.shape}")
                    else:
                        print(f"  Layer {layer_idx}: type {type(direction)}")
                        
                # Convert tensors to numpy arrays if needed
                processed_directions = {}
                for layer_idx, direction in directions.items():
                    if hasattr(direction, 'cpu'):  # PyTorch tensor
                        direction_np = direction.cpu().numpy()
                    else:
                        direction_np = np.array(direction)
                    
                    # Handle multiple vectors - take the mean or first vector
                    if len(direction_np.shape) > 1:
                        if direction_np.shape[0] > 1:
                            print(f"  Layer {layer_idx}: Multiple vectors detected ({direction_np.shape[0]}), using mean")
                            direction_np = np.mean(direction_np, axis=0)
                        else:
                            direction_np = direction_np.squeeze()
                    
                    processed_directions[layer_idx] = direction_np
                
                # Update directions with processed versions
                self.harmful_directions['directions'] = processed_directions
                print(f"Processed all direction vectors to numpy arrays")
        else:
            raise ValueError(f"Unexpected pickle format: {type(self.harmful_directions)}")
        
    def extract_steering_vector_tokens(self, layer_idx: int, top_k: int = 50, 
                                     method: str = 'direct') -> List[Tuple[str, float]]:
        """
        Extract tokens that best represent the harmful steering vector at a specific layer.
        
        This is the core method that implements steering vector token extraction:
        1. Take the learned harmful direction vector for the layer
        2. Project it through the unembedding matrix to vocabulary space
        3. Find tokens with highest logits (most promoted by this direction)
        
        Args:
            layer_idx: Layer index (negative indexing, e.g., -1, -2, etc.)
            top_k: Number of top tokens to return
            method: 'direct' for direct projection, 'normalized' for normalized direction
            
        Returns:
            List of (token, score) tuples representing the harmful concept
        """
        if self.harmful_directions is None:
            raise ValueError("Harmful directions not loaded. Call load_harmful_directions() first.")
        
        if layer_idx not in self.harmful_directions['directions']:
            raise ValueError(f"Layer {layer_idx} not found in harmful directions")
            
        if self.unembedding_matrix is None:
            raise ValueError("Unembedding matrix not available. Make sure model loaded correctly.")
        
        # Get the harmful steering vector for this layer
        steering_vector = self.harmful_directions['directions'][layer_idx]
        if len(steering_vector.shape) > 1:
            steering_vector = steering_vector.squeeze()
        
        # Check dimension compatibility
        if steering_vector.shape[0] != self.unembedding_matrix.shape[1]:
            raise ValueError(f"Dimension mismatch: steering vector has {steering_vector.shape[0]} dims, "
                           f"but unembedding matrix expects {self.unembedding_matrix.shape[1]} dims. "
                           f"Make sure you're using the correct model for these directions.")
        
        if method == 'normalized':
            # Normalize the steering vector (common in steering approaches)
            steering_vector = steering_vector / (np.linalg.norm(steering_vector) + 1e-8)
        
        # Project steering vector to vocabulary space: steering_vector @ W_U.T
        # This gives us the logit contribution this direction makes to each token
        vocab_logits = steering_vector @ self.unembedding_matrix.T  # [vocab_size]
        
        # Get top-k tokens with highest logits (most promoted by harmful direction)
        top_indices = np.argsort(vocab_logits)[-top_k:][::-1]
        
        # Convert to tokens and scores
        top_tokens = []
        for idx in top_indices:
            if self.tokenizer is not None:
                token = self.tokenizer.decode([idx])
            else:
                token = f"token_{idx}"  # Fallback if tokenizer not available
            score = vocab_logits[idx]
            top_tokens.append((token, score))
        
        return top_tokens
    
    def extract_all_layer_steering_tokens(self, top_k: int = 30, 
                                        method: str = 'direct') -> Dict[int, List[Tuple[str, float]]]:
        """
        Extract steering vector tokens for all available layers
        
        Args:
            top_k: Number of top tokens per layer
            method: Projection method ('direct' or 'normalized')
            
        Returns:
            Dictionary mapping layer_idx -> list of (token, score) tuples
        """
        if self.harmful_directions is None:
            raise ValueError("Harmful directions not loaded.")
        
        all_layer_tokens = {}
        
        for layer_idx in self.harmful_directions['hidden_layers']:
            print(f"Extracting tokens for layer {layer_idx}...")
            tokens = self.extract_steering_vector_tokens(layer_idx, top_k, method)
            all_layer_tokens[layer_idx] = tokens
        
        return all_layer_tokens
    
    def find_consistent_harmful_tokens(self, min_layers: int = 3, top_k_per_layer: int = 20) -> List[Tuple[str, float, int]]:
        """
        Find tokens that consistently appear in top positions across multiple layers.
        These represent the most stable harmful concept tokens.
        
        Args:
            min_layers: Minimum number of layers a token must appear in
            top_k_per_layer: Number of top tokens to consider per layer
            
        Returns:
            List of (token, avg_score, layer_count) tuples
        """
        all_layer_tokens = self.extract_all_layer_steering_tokens(top_k_per_layer)
        
        # Count token appearances across layers
        token_scores = defaultdict(list)
        token_layer_count = defaultdict(int)
        
        for layer_idx, tokens in all_layer_tokens.items():
            for token, score in tokens:
                clean_token = token.strip()
                token_scores[clean_token].append(score)
                token_layer_count[clean_token] += 1
        
        # Filter tokens that appear in at least min_layers
        consistent_tokens = []
        for token, scores in token_scores.items():
            if token_layer_count[token] >= min_layers:
                avg_score = np.mean(scores)
                layer_count = token_layer_count[token]
                consistent_tokens.append((token, avg_score, layer_count))
        
        # Sort by average score (descending)
        consistent_tokens.sort(key=lambda x: x[1], reverse=True)
        
        return consistent_tokens
    
    def analyze_steering_vector_magnitude(self) -> Dict[int, float]:
        """
        Analyze the magnitude of steering vectors across layers.
        Larger magnitudes indicate stronger concept representation.
        
        Returns:
            Dictionary mapping layer_idx -> vector magnitude
        """
        if self.harmful_directions is None:
            raise ValueError("Harmful directions not loaded.")
        
        layer_magnitudes = {}
        
        for layer_idx in self.harmful_directions['hidden_layers']:
            steering_vector = self.harmful_directions['directions'][layer_idx]
            if len(steering_vector.shape) > 1:
                steering_vector = steering_vector.squeeze()
            
            magnitude = np.linalg.norm(steering_vector)
            layer_magnitudes[layer_idx] = magnitude
        
        return layer_magnitudes
    
    def get_antipodal_tokens(self, layer_idx: int, top_k: int = 20) -> List[Tuple[str, float]]:
        """
        Get tokens that are most suppressed by the harmful steering vector.
        These represent the "opposite" of the harmful concept.
        
        Args:
            layer_idx: Layer index
            top_k: Number of bottom tokens to return
            
        Returns:
            List of (token, score) tuples for most suppressed tokens
        """
        if self.harmful_directions is None:
            raise ValueError("Harmful directions not loaded.")
        
        if layer_idx not in self.harmful_directions['directions']:
            raise ValueError(f"Layer {layer_idx} not found in harmful directions")
        
        # Get the harmful steering vector
        steering_vector = self.harmful_directions['directions'][layer_idx]
        if len(steering_vector.shape) > 1:
            steering_vector = steering_vector.squeeze()
        
        # Project to vocabulary space
        vocab_logits = steering_vector @ self.unembedding_matrix.T
        
        # Get bottom-k tokens (most negative logits = most suppressed)
        bottom_indices = np.argsort(vocab_logits)[:top_k]
        
        antipodal_tokens = []
        for idx in bottom_indices:
            token = self.tokenizer.decode([idx])
            score = vocab_logits[idx]  # Will be negative
            antipodal_tokens.append((token, score))
        
        return antipodal_tokens
    
    def visualize_steering_tokens(self, save_path: Optional[str] = None):
        """
        Create comprehensive visualizations of steering vector tokens
        """
        # Get data
        all_layer_tokens = self.extract_all_layer_steering_tokens(top_k=30)
        layer_magnitudes = self.analyze_steering_vector_magnitude()
        consistent_tokens = self.find_consistent_harmful_tokens(min_layers=2, top_k_per_layer=20)
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        
        # 1. Steering vector magnitudes by layer
        layers = sorted(layer_magnitudes.keys())
        magnitudes = [layer_magnitudes[layer] for layer in layers]
        
        axes[0, 0].bar(layers, magnitudes)
        axes[0, 0].set_xlabel('Layer Index')
        axes[0, 0].set_ylabel('Steering Vector Magnitude')
        axes[0, 0].set_title('Harmful Concept Strength by Layer')
        
        # 2. Top consistent harmful tokens
        if consistent_tokens:
            top_consistent = consistent_tokens[:15]
            tokens, scores, counts = zip(*top_consistent)
            
            y_pos = np.arange(len(tokens))
            axes[0, 1].barh(y_pos, scores)
            axes[0, 1].set_yticks(y_pos)
            axes[0, 1].set_yticklabels([f"{token} ({count}L)" for token, count in zip(tokens, counts)])
            axes[0, 1].set_xlabel('Average Steering Score')
            axes[0, 1].set_title('Most Consistent Harmful Tokens\n(L = number of layers)')
        
        # 3. Token scores across layers (heatmap)
        if len(all_layer_tokens) > 1:
            # Get top 10 tokens from each layer for heatmap
            heatmap_tokens = set()
            for tokens in all_layer_tokens.values():
                for token, _ in tokens[:10]:
                    heatmap_tokens.add(token.strip())
            
            heatmap_tokens = list(heatmap_tokens)[:20]  # Limit for readability
            
            # Create score matrix
            score_matrix = np.zeros((len(heatmap_tokens), len(all_layer_tokens)))
            layer_list = sorted(all_layer_tokens.keys())
            
            for j, layer_idx in enumerate(layer_list):
                layer_tokens = {token.strip(): score for token, score in all_layer_tokens[layer_idx]}
                for i, token in enumerate(heatmap_tokens):
                    score_matrix[i, j] = layer_tokens.get(token, 0)
            
            im = axes[0, 2].imshow(score_matrix, aspect='auto', cmap='Reds')
            axes[0, 2].set_xticks(range(len(layer_list)))
            axes[0, 2].set_xticklabels(layer_list)
            axes[0, 2].set_yticks(range(len(heatmap_tokens)))
            axes[0, 2].set_yticklabels(heatmap_tokens, fontsize=8)
            axes[0, 2].set_xlabel('Layer Index')
            axes[0, 2].set_title('Token Scores Across Layers')
            plt.colorbar(im, ax=axes[0, 2])
        
        # 4. Distribution of token scores for a representative layer
        if all_layer_tokens:
            rep_layer = list(all_layer_tokens.keys())[len(all_layer_tokens)//2]  # Middle layer
            rep_scores = [score for _, score in all_layer_tokens[rep_layer]]
            
            axes[1, 0].hist(rep_scores, bins=20, alpha=0.7, edgecolor='black')
            axes[1, 0].set_xlabel('Steering Score')
            axes[1, 0].set_ylabel('Number of Tokens')
            axes[1, 0].set_title(f'Score Distribution (Layer {rep_layer})')
            axes[1, 0].axvline(np.mean(rep_scores), color='red', linestyle='--', label=f'Mean: {np.mean(rep_scores):.3f}')
            axes[1, 0].legend()
        
        # 5. Comparison of promoted vs suppressed tokens
        if all_layer_tokens:
            rep_layer = list(all_layer_tokens.keys())[0]
            promoted_tokens = all_layer_tokens[rep_layer][:10]
            suppressed_tokens = self.get_antipodal_tokens(rep_layer, top_k=10)
            
            # Create comparison plot
            promoted_scores = [score for _, score in promoted_tokens]
            suppressed_scores = [abs(score) for _, score in suppressed_tokens]  # Make positive for visualization
            
            x_pos = np.arange(10)
            width = 0.35
            
            axes[1, 1].bar(x_pos - width/2, promoted_scores, width, label='Promoted (Harmful)', color='red', alpha=0.7)
            axes[1, 1].bar(x_pos + width/2, suppressed_scores, width, label='Suppressed (Safe)', color='green', alpha=0.7)
            
            axes[1, 1].set_xlabel('Token Rank')
            axes[1, 1].set_ylabel('Absolute Steering Score')
            axes[1, 1].set_title(f'Promoted vs Suppressed Tokens (Layer {rep_layer})')
            axes[1, 1].legend()
        
        # 6. Layer-wise token diversity
        layer_diversity = {}
        for layer_idx, tokens in all_layer_tokens.items():
            unique_tokens = set(token.strip() for token, _ in tokens[:20])
            layer_diversity[layer_idx] = len(unique_tokens)
        
        div_layers = sorted(layer_diversity.keys())
        diversity_counts = [layer_diversity[layer] for layer in div_layers]
        
        axes[1, 2].plot(div_layers, diversity_counts, marker='o', linewidth=2, markersize=6)
        axes[1, 2].set_xlabel('Layer Index')
        axes[1, 2].set_ylabel('Unique Tokens in Top-20')
        axes[1, 2].set_title('Token Diversity by Layer')
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def export_steering_tokens_analysis(self, output_path: str):
        """
        Export comprehensive steering token analysis to CSV
        
        Args:
            output_path: Path to save the CSV file
        """
        all_layer_tokens = self.extract_all_layer_steering_tokens(top_k=50)
        layer_magnitudes = self.analyze_steering_vector_magnitude()
        
        rows = []
        
        for layer_idx, tokens in all_layer_tokens.items():
            layer_magnitude = layer_magnitudes[layer_idx]
            
            for rank, (token, score) in enumerate(tokens, 1):
                # Also get the antipodal score for this token
                antipodal_tokens = self.get_antipodal_tokens(layer_idx, top_k=len(self.tokenizer))
                antipodal_dict = {token.strip(): score for token, score in antipodal_tokens}
                antipodal_score = antipodal_dict.get(token.strip(), 0)
                
                rows.append({
                    'layer_idx': layer_idx,
                    'layer_magnitude': layer_magnitude,
                    'token_rank': rank,
                    'token': token.strip(),
                    'steering_score': score,
                    'antipodal_score': antipodal_score,
                    'score_ratio': score / (abs(antipodal_score) + 1e-8),  # How much more promoted than suppressed
                    'normalized_score': score / layer_magnitude if layer_magnitude > 0 else 0
                })
        
        df = pd.DataFrame(rows)
        df.to_csv(output_path, index=False)
        print(f"Exported {len(df)} steering token entries to {output_path}")
        
        return df
    
    def print_steering_summary(self, top_k: int = 10):
        """
        Print a comprehensive summary of steering vector tokens
        """
        print("=" * 80)
        print("HARMFUL CONCEPT STEERING VECTOR TOKEN ANALYSIS")
        print("=" * 80)
        
        # Get data
        all_layer_tokens = self.extract_all_layer_steering_tokens(top_k=20)
        layer_magnitudes = self.analyze_steering_vector_magnitude()
        consistent_tokens = self.find_consistent_harmful_tokens(min_layers=2)
        
        print(f"\nConcept: {self.harmful_directions['concept']}")
        print(f"Model: {self.harmful_directions['model_name']}")
        print(f"Analyzed layers: {self.harmful_directions['hidden_layers']}")
        
        # Layer magnitudes
        print(f"\n📊 STEERING VECTOR MAGNITUDES BY LAYER:")
        for layer_idx in sorted(layer_magnitudes.keys()):
            magnitude = layer_magnitudes[layer_idx]
            print(f"  Layer {layer_idx:2d}: {magnitude:.4f}")
        
        # Most consistent tokens
        print(f"\n🎯 MOST CONSISTENT HARMFUL TOKENS (across ≥2 layers):")
        for i, (token, avg_score, layer_count) in enumerate(consistent_tokens[:top_k]):
            print(f"  {i+1:2d}. '{token}' (avg: {avg_score:.4f}, {layer_count} layers)")
        
        # Layer-by-layer breakdown
        print(f"\n🔍 TOP TOKENS BY LAYER:")
        for layer_idx in sorted(all_layer_tokens.keys()):
            print(f"\n  Layer {layer_idx} (magnitude: {layer_magnitudes[layer_idx]:.4f}):")
            for i, (token, score) in enumerate(all_layer_tokens[layer_idx][:top_k]):
                print(f"    {i+1:2d}. '{token}': {score:.4f}")
        
        # Antipodal tokens for one layer
        if all_layer_tokens:
            rep_layer = list(all_layer_tokens.keys())[0]
            antipodal = self.get_antipodal_tokens(rep_layer, top_k=top_k)
            print(f"\n🔄 MOST SUPPRESSED TOKENS (Layer {rep_layer}):")
            for i, (token, score) in enumerate(antipodal):
                print(f"    {i+1:2d}. '{token}': {score:.4f}")

# Example usage
def main():
    """
    Example usage of the HarmfulSteeringTokenExtractor
    """
    # Initialize extractor - you need to use the SAME model that was used to create the directions
    # Based on your pickle file name, it looks like you used LLaMA 3.1 8B
    print("Initializing with LLaMA 3.1 8B model...")
    extractor = HarmfulSteeringTokenExtractor("meta-llama/Meta-Llama-3.1-8B-Instruct")
    
    try:
        # Load the harmful directions (the steering vectors)
        extractor.load_harmful_directions("/home/ubuntu/krishiv-llm/neural_controllers/directions/rfm_harmful_llama_3_8b_it.pkl")
        
        # Print comprehensive analysis
        extractor.print_steering_summary(top_k=15)
        
        # Create visualizations
        extractor.visualize_steering_tokens("harmful_steering_analysis.png")
        
        # Export detailed CSV
        df = extractor.export_steering_tokens_analysis("harmful_steering_tokens.csv")
        
        # Example: Get tokens for a specific layer
        print("\n" + "="*50)
        print("EXAMPLE: First available layer harmful tokens")
        print("="*50)
        
        available_layers = list(extractor.harmful_directions['directions'].keys())
        if available_layers:
            first_layer = available_layers[0]
            layer_tokens = extractor.extract_steering_vector_tokens(first_layer, top_k=20)
            for i, (token, score) in enumerate(layer_tokens):
                print(f"{i+1:2d}. '{token}': {score:.4f}")
        else:
            print("No layers found in directions!")
            
    except Exception as e:
        print(f"Error: {e}")
        print("\nDebugging info:")
        print("If you get a dimension mismatch error, it means:")
        print("1. You're using directions created with a different model")
        print("2. Your directions have 4096 dimensions (LLaMA) but you're using GPT-2 (768 dims)")
        print("3. Make sure to use the same model that was used to create the steering vectors")
        print("\nTry changing the model initialization to match your directions file.")

if __name__ == "__main__":
    main()